%        File: proposal.tex
%     Created: Wed Mar 04 02:00 PM 2015 C
% Last Change: Wed Mar 04 02:00 PM 2015 C
%
\documentclass[a4paper]{article}

\usepackage{geometry}
\usepackage{amsmath,amssymb}
\usepackage{cite}

\title{Proposal: Parallel Randomized SVD for Low Rank Matrix Approximation}
\date{\today}
\author{Sameer Tharakan, Keith Kelly}
\begin{document}
\maketitle

The singular value decomposition (SVD) is ubiquitous in science and engineering computations. 
Unfortunately, computation of the SVD is oftentimes prohibitively expensive; for a matrix $A\in\mathbb{R}^{m \times n}$ with $m\geq n$, computing the SVD costs $\mathcal{O}(mn^2)$ \cite{golub2012matrix}.
For a very large matrix this is not feasible.
In many cases, computing the exact, entire SVD is not necessary and an approximation is sufficient provided the spectrum decays. 
This idea is used in image processing, learning tasks, and inverse problems to name a few.

Fortunately, there exist a more recent class of algorithms for the low rank approximation of the SVD using randomized techniques.
To compute a rank $k$ approximation of $A$, the cost is $\mathcal{O}(mn\log(k) + k^2(m+n))$ and the error is bounded by $n\sigma_{k+1}$ \cite{halko2011finding}.

Implementing a SVD for a distributed memory architecture is a nontrivial task.
We intend to implement a few carefully chosen randomized parallel SVD algorithms as presented in \cite{halko2011finding}, \cite{kontoghiorghes2005handbook}.
We will compare these algorithms against a state of the art SVD library.
Challenges in implementing these algorithms include avoiding communication \cite{ballard2010minimizing} and restructuring the algorithm to take advantage of multiple threads and processors.

\bibliography{rsvd.bib}{
\bibliographystyle{plain}}
\end{document}


